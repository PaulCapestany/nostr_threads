package main

import (
	"context"
	"encoding/json"
	"errors"
	"fmt"
	"log"
	"net/http"
	_ "net/http/pprof"
	"os"
	"os/signal"
	"sort"
	"strings"
	"sync"
	"syscall"
	"time"

	"github.com/paulcapestany/nostr_shared/config"
	"github.com/paulcapestany/nostr_shared/couchbase"

	"github.com/couchbase/gocb/v2"
	"github.com/gorilla/mux"
)

// JSON structure of our threads' embedding aspect needs to look similar to this:
// {
// 	  "x_embeddings": {
//   	  "mxbai-embed-large": {
// 		  "mxbai-embed-large-embeddings": [[0.017701002, -0.0052093007]],
// 		  "last_processed_token_position": 512  // The position in x_cat_content where embedding ended.
// 	    },
// 	    "nomic-embed-text": {
// 		  "nomic-embed-text-embeddings": [[-0.020272737, 0.020430557]],
// 		  "last_processed_token_position": 1000
// 	    }
// 	  }
//  }

// nostr_threads flow
// gets an arbitrary message ID, first checks if it's already in the all-nostr-events bucket, if not, uses nak to fetch it

// Message represents a Nostr message structure
type Message struct {
	// TODO: must implement _seen_at !!!!!!!!!
	SeenAtFirst int64         `json:"_seen_at_first"`
	CreatedAt   int64         `json:"created_at"`
	ID          string        `json:"id"`
	Content     interface{}   `json:"content"`
	Kind        int           `json:"kind"`
	Pubkey      string        `json:"pubkey"`
	Sig         string        `json:"sig"`
	Tags        []interface{} `json:"tags"`
	// NOTE: ParentID and Depth fields are not present in the JSON payload, we have to recursively search/construct them
	ParentID string `json:"parent_id"`
	Depth    int    `json:"depth"`
}

// Thread represents a flattened Nostr thread structure
type Thread struct {
	// NOTE: a thread's CreatedAt, ID, Kind, and Pubkey are the same as the first message in the thread (the root Nostr message)
	ID string `json:"id"`
	// TODO: must implement _seen_at !!!!!!!!!
	CreatedAt   int64     `json:"created_at"`
	LastMsgAt   int64     `json:"last_msg_at"`
	SeenAtFirst int64     `json:"_seen_at_first"`
	MsgCount    int       `json:"m_count"`
	Kind        int       `json:"kind"`
	Pubkey      string    `json:"pubkey"`
	Messages    []Message `json:"messages"`
	// NOTE: fields starting with "x_" will be generated by us
	XConcatenatedContent string                   `json:"x_cat_content"`
	XEmbeddings          map[string]EmbeddingInfo `json:"x_embeddings"`
}

// EmbeddingInfo holds the embeddings and token position for a model
type EmbeddingInfo struct {
	Embeddings                 map[string][][]float32 `json:"-"` // Use map for dynamic field
	LastProcessedTokenPosition int                    `json:"last_processed_token_position"`
}

// MarshalJSON will handle the dynamic JSON structure for embeddings
func (ei EmbeddingInfo) MarshalJSON() ([]byte, error) {
	// Create a temporary struct to hold the final JSON
	type embeddingAlias EmbeddingInfo
	temp := embeddingAlias(ei)

	// Manually construct the embeddings field with the model name as the key
	embeddingsField := make(map[string]interface{})
	for modelName, embeddings := range ei.Embeddings {
		// Generate the key by appending the model name
		key := fmt.Sprintf("%s-embeddings", modelName)
		embeddingsField[key] = embeddings
	}

	// Convert temp struct into a map
	finalJSON := make(map[string]interface{})
	finalJSON["last_processed_token_position"] = temp.LastProcessedTokenPosition
	for key, value := range embeddingsField {
		finalJSON[key] = value
	}

	return json.Marshal(finalJSON)
}

func init() {
	// Log to standard output
	log.SetOutput(os.Stdout)
	// Set log flags for more detailed output
	log.SetFlags(log.LstdFlags | log.Lshortfile)
	go func() {
		// this was for pprof profiling
		log.Println(http.ListenAndServe("0.0.0.0:6060", nil))
	}()
}

func main() {
	// Initialize Couchbase connection
	config.Setup()
	cluster, _, _, _, err := couchbase.InitializeCouchbase()
	if err != nil {
		log.Fatalf("Error initializing Couchbase: %v", err)
	}
	defer cluster.Close(nil)

	// Set up the HTTP server
	r := mux.NewRouter()
	r.HandleFunc("/nostr/update_thread", func(w http.ResponseWriter, r *http.Request) {
		UpdateThreadHandler(w, r, cluster)
	}).Methods("POST")

	srv := &http.Server{
		Handler:      r,
		Addr:         "0.0.0.0:8081",
		WriteTimeout: 60 * time.Second,
		ReadTimeout:  60 * time.Second,
		IdleTimeout:  90 * time.Second,
	}

	ctx, stop := signal.NotifyContext(context.Background(), os.Interrupt, syscall.SIGTERM)
	defer stop()

	done := make(chan bool)
	var wg sync.WaitGroup
	wg.Add(1)

	go func() {
		defer wg.Done()
		<-ctx.Done()

		log.Println("Shutting down server...")

		shutdownCtx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
		defer cancel()

		srv.SetKeepAlivesEnabled(false)
		if err := srv.Shutdown(shutdownCtx); err != nil {
			log.Fatalf("Could not gracefully shut down the server: %v\n", err)
		}
		close(done)
	}()

	log.Println("Starting server on :8081")
	if err := srv.ListenAndServe(); err != nil && err != http.ErrServerClosed {
		log.Fatalf("Could not listen on :8081: %v\n", err)
	}

	<-done
	log.Println("Server stopped")
	wg.Wait()
}

func retryOperation(operation func() error, retries int, messageIDsToQuery []string) error {
	for i := 0; i < retries; i++ {
		err := operation()
		if err == nil {
			return nil
		}
		log.Printf("Retry %d/%d failed: %v messageIDsToQuery:%v", i+1, retries, err, messageIDsToQuery)
		time.Sleep(2 * time.Second) // Exponential backoff can be implemented here
	}
	return fmt.Errorf("operation failed after %d retries", retries)
}

const trustOlderTimestamps int64 = 1725897900 // Sep 9, 2024 4:05 PM as Unix timestamp

// isMessageTimestampTrustworthy checks if a message's created_at is trustworthy for appending to x_cat_content
func isMessageTimestampTrustworthy(messageCreatedAt int64, lastMsgAt int64, seenAtFirst *int64) bool {
	if seenAtFirst != nil {
		// If the message has a _seen_at_first field, we trust it
		return true
	}

	if messageCreatedAt > lastMsgAt {
		// If the message's created_at is newer than the thread's last_msg_at, we trust it
		return true
	}

	if messageCreatedAt < trustOlderTimestamps {
		// If the message's created_at is older than the trustOlderTimestamps, we trust it for backfilling
		return true
	}

	return false
}

// SanitizeContent cleans up the content by removing or replacing unwanted characters
func SanitizeContent(content string) string {
	return strings.Join(strings.Fields(content), " ") // Reduce multiple spaces to a single space
}

// TODO: UpdateThreadHandler needs to work concurrently with multiple threads
// UpdateThreadHandler handles requests to update threads and ensure the x_cat_content is append-only
// UpdateThreadHandler handles requests to update threads and ensure the x_cat_content is append-only
func UpdateThreadHandler(w http.ResponseWriter, r *http.Request, cluster *gocb.Cluster) {
	// Decode payload
	var payload struct {
		ID      string  `json:"id"`
		Message Message `json:"message"`
	}
	err := json.NewDecoder(r.Body).Decode(&payload)
	if err != nil {
		log.Printf("Failed to decode payload: %v", err)
		http.Error(w, err.Error(), http.StatusBadRequest)
		return
	}

	log.Printf("Received payload with ID: %+v\n", payload.ID)

	// Couchbase setup
	ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
	defer cancel()
	bucket := cluster.Bucket(config.EnvPrefix + "threads")
	collection := bucket.DefaultCollection()

	// Fetch existing thread
	var existingThread Thread
	getResult, err := collection.Get(payload.ID, nil)
	if err == nil {
		err = getResult.Content(&existingThread)
		if err != nil {
			log.Printf("Failed to decode existing thread content: %v", err)
			http.Error(w, err.Error(), http.StatusInternalServerError)
			return
		}
	}

	// Process messages and fetch new ones
	messageIDsToQuery := []string{payload.ID}
	log.Println("Calling messageFetcher with messageIDsToQuery: ", messageIDsToQuery)
	var allUniqueThreadMessages []Message
	alreadyQueriedIDs := make(map[string]bool)
	foundMessageIDs := make(map[string]bool)
	err = retryOperation(func() error {
		return messageFetcher(ctx, messageIDsToQuery, &allUniqueThreadMessages, cluster, alreadyQueriedIDs, foundMessageIDs)
	}, 3, messageIDsToQuery)

	if err != nil {
		log.Printf("Failed to fetch messages: %v", err)
		http.Error(w, err.Error(), http.StatusInternalServerError)
		return
	}

	// Sort messages by created_at
	sort.Slice(allUniqueThreadMessages, func(i, j int) bool {
		return allUniqueThreadMessages[i].CreatedAt < allUniqueThreadMessages[j].CreatedAt
	})

	threadedProcessedMessages, err := processMessageThreading(allUniqueThreadMessages)
	if err != nil {
		log.Printf("Failed to process message threading: %v messageIDsToQuery: %v", err, messageIDsToQuery)
		http.Error(w, err.Error(), http.StatusInternalServerError)
		return
	}

	// Generate new x_cat_content based on append-only rules
	var allMessagesContent string
	for _, msg := range threadedProcessedMessages {
		sanitizedContent := SanitizeContent(fmt.Sprintf("%s", msg.Content))
		if isMessageTimestampTrustworthy(msg.CreatedAt, existingThread.LastMsgAt, &msg.SeenAtFirst) {
			// Only append content from messages we trust
			allMessagesContent += fmt.Sprintf("%s  ", sanitizedContent)
		}
	}

	// Update last_msg_at based on the latest trustworthy message
	var lastMsgAt int64
	for _, msg := range threadedProcessedMessages {
		if msg.CreatedAt > lastMsgAt {
			lastMsgAt = msg.CreatedAt
		}
	}

	// Construct the updated thread
	newThread := Thread{
		CreatedAt:            threadedProcessedMessages[0].CreatedAt,
		SeenAtFirst:          threadedProcessedMessages[0].SeenAtFirst,
		LastMsgAt:            lastMsgAt,
		MsgCount:             len(threadedProcessedMessages),
		ID:                   threadedProcessedMessages[0].ID,
		Kind:                 threadedProcessedMessages[0].Kind,
		Pubkey:               threadedProcessedMessages[0].Pubkey,
		Messages:             threadedProcessedMessages,
		XConcatenatedContent: allMessagesContent,
	}

	if newThread.ID == messageIDsToQuery[0] {
		log.Printf("SUCCESS: new thread: %v", newThread.ID)
	} else {
		// log.Printf("SUCCESS: updated thread: %v via messageIDsToQuery: %v\n", newThread.ID, messageIDsToQuery)
		log.Printf("SUCCESS: updated thread: %v", newThread.ID)
	}

	// Merge any existing embeddings
	if existingThread.XEmbeddings != nil {
		newThread.XEmbeddings = existingThread.XEmbeddings
	}

	// Upsert the updated thread into Couchbase
	err = retryOperation(func() error {
		_, err = collection.Upsert(newThread.ID, newThread, nil)
		return err
	}, 3, messageIDsToQuery)
	if err != nil {
		log.Printf("Failed to upsert thread: %v", err)
		http.Error(w, err.Error(), http.StatusInternalServerError)
		return
	}

	// Respond with the updated thread
	responseJSON, err := json.Marshal(newThread)
	if err != nil {
		log.Printf("Failed to marshal response JSON: %v", err)
		http.Error(w, err.Error(), http.StatusInternalServerError)
		return
	}
	w.WriteHeader(http.StatusOK)
	w.Header().Set("Content-Type", "application/json")
	w.Write(responseJSON)
}

func messageFetcher(ctx context.Context, messageIDs []string, allUniqueThreadMessages *[]Message, cluster *gocb.Cluster, alreadyQueriedIDs map[string]bool, foundMessageIDs map[string]bool) error {
	if cluster == nil {
		log.Println("Cluster connection is not initialized.")
		return fmt.Errorf("cluster connection is not initialized")
	}

	messageIDsToQuery := make([]string, 0)
	messageMap := make(map[string]Message)
	for _, msg := range *allUniqueThreadMessages {
		messageMap[msg.ID] = msg
	}

	for _, id := range messageIDs {
		if alreadyQueriedIDs[id] {
			continue // Skip IDs already marked as missing
		}

		query := fmt.Sprintf(`WITH referencedMessages AS (
            SELECT d.*
            FROM `+"`all-nostr-events`._default._default"+` AS d
            USE KEYS "%s"

            UNION

            SELECT refMessage.*
            FROM `+"`all-nostr-events`._default._default"+` AS refMessage
            USE INDEX (kind_and_event_lookup USING GSI)
            WHERE refMessage.kind = 1 AND (ANY t IN refMessage.tags SATISFIES t[0] = "e" AND t[1] = "%s" END)
        )
        SELECT message.content, message.created_at, message.id, message.kind, message.pubkey, message.sig, message.tags
        FROM referencedMessages AS message`, id, id)

		results, err := cluster.Query(query, nil)
		if err != nil {
			log.Printf("Failed to execute query for ID %s: %v", id, err)
			continue
		} else {
			alreadyQueriedIDs[id] = true
		}

		for results.Next() {
			select {
			case <-ctx.Done():
				return ctx.Err()
			default:
			}

			var msg Message
			if err := results.Row(&msg); err != nil {
				log.Printf("Failed to parse message: %v", err)
				continue
			}
			if msg.Kind != 1 {
				continue
			}

			contentStr := fmt.Sprintf("%v", msg.Content)
			msg.Content = contentStr

			for _, tag := range msg.Tags {
				tagSlice, ok := tag.([]interface{})
				if !ok || len(tagSlice) < 2 || tagSlice[0] != "e" {
					continue
				}
				if idStr, ok := tagSlice[1].(string); ok && !contains(foundMessageIDs, idStr) && !contains(alreadyQueriedIDs, idStr) {
					messageIDsToQuery = append(messageIDsToQuery, idStr)
				}
			}
			if !containsMessage(foundMessageIDs, msg.ID) {
				messageIDsToQuery = append(messageIDsToQuery, msg.ID)
				*allUniqueThreadMessages = append(*allUniqueThreadMessages, msg)
				foundMessageIDs[msg.ID] = true
			}
		}
		if err := results.Err(); err != nil {
			log.Printf("Error iterating results: %v", err)
		}
	}

	// Recursively fetch messages for newly discovered IDs if there are any
	if len(messageIDsToQuery) > 0 {
		return messageFetcher(ctx, messageIDsToQuery, allUniqueThreadMessages, cluster, alreadyQueriedIDs, foundMessageIDs)
	}
	// log.Printf("alreadyQueriedIDs: %v", alreadyQueriedIDs)
	log.Printf("foundMessageIDs: %v", foundMessageIDs)
	return nil
}

func containsMessage(messages map[string]bool, id string) bool {
	_, exists := messages[id]
	return exists
}

func contains(ids map[string]bool, id string) bool {
	_, exists := ids[id]
	return exists
}

func processMessageThreading(allUniqueThreadMessages []Message) ([]Message, error) {
	var messagesNestedInAThread []Message

	// Find the original message
	var originalMessage *Message
	var maxMentions int
	for i, msg := range allUniqueThreadMessages {
		etags := getETags(msg.Tags)
		if len(etags) == 0 {
			// Count the number of times the message's ID is mentioned in other messages' etags
			mentions := 0
			for _, otherMsg := range allUniqueThreadMessages {
				if otherMsg.ID != msg.ID {
					for _, etag := range getETags(otherMsg.Tags) {
						if len(etag) > 1 && etag[1] == msg.ID {
							mentions++
						}
					}
				}
			}

			if originalMessage == nil || mentions > maxMentions {
				originalMessage = &allUniqueThreadMessages[i]
				maxMentions = mentions
				// log.Printf("Warning: potential error/fail? (mentions > maxMentions) \"originalMessage.ID\": %v", originalMessage.ID)
			} else if mentions == maxMentions {
				return nil, errors.New("multiple original messages found with the same number of mentions")
			}
		}
	}

	if originalMessage == nil {
		// log.Printf("original message not found: %v", originalMessage.ID)
		return nil, errors.New("WARN: original message not found")
		// TODO: grab message from another relay?
	}

	originalMessage.Depth = 1
	messagesNestedInAThread = append(messagesNestedInAThread, *originalMessage)
	allUniqueThreadMessages = removeMessage(allUniqueThreadMessages, originalMessage.ID)

	// Process direct replies to the original message
	for i := 0; i < len(allUniqueThreadMessages); i++ {
		msg := allUniqueThreadMessages[i]
		etags := getETags(msg.Tags)
		if len(etags) == 1 && etags[0][1] == originalMessage.ID {
			msg.Depth = 2
			msg.ParentID = originalMessage.ID
			messagesNestedInAThread = append(messagesNestedInAThread, msg)
			allUniqueThreadMessages = append(allUniqueThreadMessages[:i], allUniqueThreadMessages[i+1:]...)
			i--
		}
	}

	// Process remaining messages
	for len(allUniqueThreadMessages) > 0 {
		msg := allUniqueThreadMessages[0]
		etags := getETags(msg.Tags)

		var processed bool

		if len(etags) == 1 {
			// Case a: Message has only one etag
			if parentMsg := findMessageByID(messagesNestedInAThread, etags[0][1]); parentMsg != nil {
				msg.Depth = parentMsg.Depth + 1
				msg.ParentID = parentMsg.ID
				messagesNestedInAThread = append(messagesNestedInAThread, msg)
				processed = true
			}
		} else if len(etags) > 1 {
			// Case b: Message has multiple etags and one of them has etag[3] == "reply"
			for _, etag := range etags {
				if len(etag) >= 4 && etag[3] == "reply" {
					if parentMsg := findMessageByID(messagesNestedInAThread, etag[1]); parentMsg != nil {
						msg.Depth = parentMsg.Depth + 1
						msg.ParentID = parentMsg.ID
						messagesNestedInAThread = append(messagesNestedInAThread, msg)
						processed = true
						break
					}
				}
			}

			if !processed {
				// Case c: Message has multiple etags and none of them have etag[3] == "reply"
				var maxDepth int
				var parentMsg *Message
				for _, etag := range etags {
					if msg := findMessageByID(messagesNestedInAThread, etag[1]); msg != nil && msg.Depth > maxDepth {
						maxDepth = msg.Depth
						parentMsg = msg
					}
				}
				if parentMsg != nil {
					msg.Depth = parentMsg.Depth + 1
					msg.ParentID = parentMsg.ID
					messagesNestedInAThread = append(messagesNestedInAThread, msg)
					processed = true
				}
			}
		}

		if processed {
			allUniqueThreadMessages = allUniqueThreadMessages[1:]
		} else {
			// If none of the above cases match, skip the message
			allUniqueThreadMessages = allUniqueThreadMessages[1:]
		}
	}

	return messagesNestedInAThread, nil
}

func removeMessage(messages []Message, id string) []Message {
	for i, msg := range messages {
		if msg.ID == id {
			return append(messages[:i], messages[i+1:]...)
		}
	}
	return messages
}

func getETags(tags []interface{}) [][]string {
	var etags [][]string
	for _, tag := range tags {
		if tagArr, ok := tag.([]interface{}); ok && len(tagArr) > 0 && tagArr[0] == "e" {
			var etag []string
			for _, t := range tagArr {
				if tStr, ok := t.(string); ok {
					etag = append(etag, tStr)
				}
			}
			etags = append(etags, etag)
		}
	}
	return etags
}

func findMessageByID(messages []Message, id string) *Message {
	for i := range messages {
		if messages[i].ID == id {
			return &messages[i]
		}
	}
	return nil
}
